Здесь будет информация о различных вариантах развертывания приложений
=====================================================================

HEROKU
------
Установка Heroku в случай с WSL возможна командой curl https://cli-assets.heroku.com/install.sh | sh

I. Развертывание без статических файлов и использования docker 
--------------------------------------------------------------
1. Обновить файл Pipfile.lock: 
pipenv lock
   
2. Создать файл Procfile и прописать в нем (если папка конфигурации проекта называется config): 
web: gunicorn config.wsgi --log-file -

3. Установить в качестве боевого сервера приложение gunicorn:
pipenv install gunicorn

4. Изменить настройки в файле settings.py, указав хосты, которые должно обслуживать приложение:
...
ALLOWED_HOSTS = ['*']
...

5. Залогиниться на Heroku
heroku login

6. Создать приложение heroku (опционально можно указать название создаваемого сайта):
heroku create <желаемое appname>

7. Совершить веб-хук, в данном случае сохранить настройки для отправки кода в репо и на Heroku (???)
heroku git:remote -a <полученное от heroku appname>

8. Для того, чтобы heroku проигнорировал статические файлы (images, css, js), следует выполнить команду:
heroku config:set DISABLE_COLLECTSTATIC=1

9. Отправить код на heroku:
git push heroku master

10. Установить уровень сервисов, оказываемых heroku, на низкой, бесплатной отметке:
heroku ps:scale web=1

11. Открыть сайт: 
heroku open

II. Развертывание с использованием статических файлов, но без docker
--------------------------------------------------------------------
К вышеприведенному алгоритму добавим пункты 7.1.1.-7.1.2
7.1.1. Установить пакет для работы со статическими файлами:
pipenv install whitenoise

7.1.2. В настройках (файл settings.py) указать:
a) в списке INSTALLED_APPS (обязательно перед django.contrib.staticfiles):
whitehoise.runserver_nostatic

б) в списке MIDDLEWARE (третьим сверху):
whitenoise.middleware.WhiteNoiseMiddleware

в) далее в файле settings.py (добавить то, что еще не указано): 
STATIC_ROOT = os.path.join(BASE_DIR, 'staticfiles')
STATIC_URL = /static/
STATICFILES_DIRS = [os.path.join(BASE_DIR, 'static')]
STATICFILES_STORAGE =  'whitenoise.storage.CompressedManifestStaticFilesStorage'

Разумеется, что в этом случае п. 8 из вышеприведенного алгоритма исключается.

III. Развертывание с использованием docker
------------------------------------------
Разработка приложения ведется на основе docker-compose файлов

1. Установить whitenoise и прописать нужные строки в файле #settings.py
docker-compose exec web pipenv install whitenoise

2. Собрать статические файлы
docker-compose exec web python manage.py collectstatic

3. Установить gunicorn 
docker-compose exec web pipenv install gunicorn

4. Прописать нужные строки в docker-compose-prod.yml
command: gunicorn config.wsgi -b 0.0.0.0:8000

5. Установить приложение для переноса БД (???)
docker-compose exec web pipenv install dj-database-url

6. Добавить строки о БД в настройки
import dj_database_url
db_from_env = dj_database_url.config(conn_max_age=500)
DATABASES['default'].update(db_from_env)

7. Добавить в настройки файла # settings.py
...
SECURE_PROXY_SSL_HEADER = ('HTTP_X_FORWARDED_PROTO', 'https')
...

8. Создать локальный репо и доводим его до коммита

9. Залогиниться на heroku 
$ heroku login

10. Создать yml-файл для создания контейнера на heroku 
# heroku.yml
setup:
    addons:
    - plan: heroku-postgresql
build:
    docker:
        web: Dockerfile
release:
    image: web
    command:
    - python manage.py collectstatic --noinput
run:
    web: gunicorn bookstore_project.wsgi

11. Создать приложение с желаемым названием <appname> на .herokuapp.com (его можно сразу же записать в settings.py)
heroku create <appname>

12. На сайте heroku ввести значения необходимых переменных окружения

13. Создать (или подтвердить?) желание развернуть приложение в контейнере
$ heroku stack:set container -a <appname>

14. Создать БД
$ heroku addons:create heroku-postgresql:hobby-dev -a <appname>

15. Связать локальное репо с удаленным репо на heroku и залить код
$ heroku git:remote -a <appname>
$ heroku git push heroku master

16. Выполнить миграции для создания таблиц в новой БД и создать суперюзера
$ DCPM migrate
$ DCPM createsuperuser

17. Открыть приложение в браузере
$ heroku open -a <appname>

-----
About requirements.txt
-----
В ubuntu при формировании этого файла создается строка 'pkg-resources', мешающая правильной установке пакетов. С целью ее удаления предлагается использовать следующую команду (проверено - работает):
pip freeze | grep -v "pkg-resources" > requirements.txt


ПОЛУЧЕНИЕ SSL-СЕРТИФИКАТА
-------------------------
Используем бесплатный сервис Let's Encrypt (https://letsencrypt.org).
Сначала рекомендуется выбрать на сайте требуемые ОС и версии дистрибутивов. Далее все можно делать в командной строке:
1. sudo snap install --classic-certbot - устанавливаем пакет
2. sudo ln -s /snap/bin/certbot /usr/bin/certbot - создаем ссылку
3. sudo certbot --nginx - запускаем сканирование и настройку nginx для получения сертификата
4. отвечаем "y" на ряд вопросов (эл. почту указываем настоящую) и проверяем, те ли домены нашел бот (если те, то просто жмем на Enter)
5. в случае, если сертификаты будут созданы, ссылки на них можно увидеть в файле nginx.conf проекта, а в брауземе схема url автоматически поменяется на https://


ДЕПЛОЙ НА AWS С ПОМОЩЬЮ UWSGI & NGINX
-------------------------------------
Прежде всего, необходимо поставить приложение uwsgi: находясь в виртуальной среде выполнить команду
pip install uwsgi
и установить сервер nginx:
sudo apt install nginx

1. В каталоге config проекта cоздаем файл uwsgi.ini с примерно такими настройками:

[uwsgi]

projectname = config # название конфигурационного каталога (где лежит settings.py и др.)
base = /home/ubuntu/deploy_uwsgi
master = true
virtualenv = /home/ubuntu/deploy_uwsgi/env
pythonpath = %(base)
chdir = %(base)
env = DJANGO_SETTINGS_MODULE=%(projectname).settings
module = config.wsgi:application
socket = /tmp/%(projectname).sock
chmod-socket = 666
disable-logging=True

2. В том же каталоге создаем файл nginx.conf, где для начала прописываем следующее:

upstream config {
        server unix:///tmp/config.sock;
}

server {
        server_name www.docent63.ru docent63.ru;
        location / {
                include /etc/nginx/uwsgi_params;
                uwsgi_pass config;
        }

 
3. На сервере необходимо применить созданные настройки, для чего:

3.1. в основном конфигурационном файле сервера nginx по адресу /usr/nginx/nginx.conf прописываем в словаре http {
	include /home/ubuntu/deploy_uwsgi/config/nginx.conf;
	...
}

3.2. запускаeм сервер nginx: sudo systemctl start nginx (другие команды: status, stop)
и приложение (по сути, тоже сервер) uwsgi (команда работает из одного каталога с файлом - инициирует этот самый файл): uwsgi --ini uwsgi.ini
Для удобства просмотра статуса сервера и его запуска/остановки создал следующий скрипт (и поместил его как файл kick по адресу /usr/local/bin - находящиеся здесь файлы могут быть запущены из любого места ФС): 

if ps aux | grep uwsgi | grep -v grep > /dev/null # проверяем, если процесс от uwsgi
then
        echo "Now uwsgi-server is running."

else
        echo "Now uwsgi-server in stopping"
fi

read -p "Do you wish to change this status? (y/n) " yn

ps aux | grep uwsgi | grep -v grep > kickfile # пишем результат поиска процессов в файл 
file=kickfile

case $yn in # проверяем наличие в файле содержимого - если он не пустой, останавливаем uwsgi (kill -9), а если он пуст (т.е. процессов uwsgi не обнаружено), запускаем uwsgi-сервер (файл kick создается и тут же дропится)
        [Yy]* ) if [[ -s $file ]]; then ps aux | grep uwsgi | grep -v grep | awk '{print $2}' | xargs kill -9 && echo "Stopped"; else /home/ubuntu/deploy_uwsgi/env/bin/uwsgi --ini /home/ubuntu/deploy_uwsgi/config/uwsgi.ini; fi; rm kickfile 2> /dev/null; exit;;
        [Nn]* ) rm kickfile 2> /dev/null; exit;;
esac


ДЕПЛОЙ С GUNICORN & NGINX
-------------------------
В виртуальном окружении устанавливается gunicorn: pip istall gunicorn (предполагается, что nginx к этому моменту уже установлен)

1. Создаются файлы, связанные с gunicorn:
1.1. /etc/systemd/system/gunicorn.socket
[Unit]
Description=gunicorn socket

[Socket]
ListerStream=/run/gunicorn.sock

[Install]
WantedBy=sockets.target

1.2. /etc/systemd/system/gunicorn.service
[Unit]
Description=gunicorn daemon
Requires=gunicorn.socket
After=network.target

[Service]
User=mick
Group=www-data
WorkingDirectory=/home/mick/django_projects/deploy_gunicorn
ExecStart=/home/mick/django_projects/deploy_gunicorn/venv/bin/gunicorn \
	--access-logfile - \
	--workers 3 \
	--bind unix:/run/gunicorn.sock \
	config.wsgi:application

[Install]
WantedBy=multy-user.target

Важно помнить, что, как правило, каталог конфигураций проекта у меня называется config, и если его приходится переименовывать вручную, что это надо делать (помимо названия самой папки) еще в трех файлах: manage.py, wsgi.py и settings.py (здесь в двух местах: настройках urls и wsgi). В  этом примере указаны пути для конкретного проекта и в любом другом случае должны быть изменены. 

2. Настройки в созданных файлах должны быть активированы: 
sudo systemctl start gunicorn.socket
sudo systemctl enable gunicorn.socket
sudo systemctl status gunicorn.socket

3. Настройка сервера nginx (может быть использована и уже использована для случая с uwsgi)
Вместо создания файла nginx.conf в конфиге проекта логичнее работать с домашним каталогом nginx:
3.1. создаем файл /etc/nginx/sites-available/deploy_gunicorn 
server {
	listen 80;
	server_name docent63.ru www.docent63.ru;

	location / {
		include proxy_params;
		proxy_pass http://unix:/run/gunicorn.sock;
	}
}

3.2. Далее из этого каталога (как понятно из его названия, содержащего настройки имеющихся в наличии сайтов) делается ссылка на каталог доступных сайтов:
sudo ln -s /etc/nginx/sites-available/deploy_gunicorn /ect/nginx/sites-enabled

3.3. тестируем настройки и перезапускаем nginx
sudo nginx -t
sudo systemctl restart nginx
sudo ufw allow 'Nginx Full' (открываем файервол для разрешения нормального трафика на 80 порту, но это опционально, должно работать и так)

На этом настройка gunicorn+ngins заканчивается, браузер должен отображать страницу задеплоенного сайта.


BASH-скрип для запуска uwsgi-сервера на домашней машине командой check 
-----------------------------------------------------------------------

#! /bin/bash

base_dir=/home/mick/DjangoProjects/docent63

if ps aux | grep uwsgi | grep -v grep >/dev/null 
then
	echo "uWSGI-server is running."
else
	echo "uWSGI-server is stopping."
fi

if echo "$PWD" | grep "$LOGNAME" > /dev/null
	then
	read -p "Do you wish to change this status? (y/n) " yn

	ps aux | grep uwsgi | grep -v grep > kickfile

	file=kickfile

	case $yn in
        	[Yy]* ) if [[ -s $file ]] 
			then 
				mv "$base_dir"/config/_dev.py "$base_dir"/config/dev.py
			        ps aux | grep uwsgi | grep -v grep \
				| awk '{print $2}' | \
				xargs kill -9 && echo "Stopped" && rm kickfile 
			else 
				mv "$base_dir"/config/dev.py "$base_dir"/config/_dev.py
				rm kickfile && \
				"$base_dir"/env/bin/uwsgi --ini "$base_dir"/config/uwsgi.ini 
			fi 
			exit;;
        	[Nn]* ) rm kickfile 
			exit;;
	esac

else
	echo 'Try it from local user area.'
fi


CELERY-инициализация на сервере AWS
-----------------------------------
При развертывании приложения на сервере (AWS) возникла проблема: сервис celery  запускался только в активном режиме, т.е. после команды запуска перехватывал управление терминалом, и при закрытии терминала отказывался обрабатывать задачи, которые перед ним ставились. Было перепробовано несколько решений, в т.ч. и те, которые в конце команды запуска используют, например, & или --detach. Но работающим решением стало создание соответвующей службы: celery.service. Файл с таким названием создается в /etc/systemd/system/ и включает следующее:

[Unit]
Description=Celery Service
After=network.target

[Service]
User=your_username
WorkingDirectory=/home/your_username/your_projdir
Environment="PATH=/home/your_username/your_projdir/venv/bin"
ExecStart=/home/your_username/your_projdir/venv/bin/celery worker -A celery_worker.celery --loglevel=info
# здесь команду 'worker -A celery_worker.celery' я заменил на свою 'celery -A celery config worker -l info'

[Install]
WantedBy=default.target

Далее запуск celery осуществляется обычным способом: sudo service celery start (другие полезные команды: status и stop). 
Важно!!! Перед запуском celery необходимо перезапустить все фоновые процессы следующей командой: 
sudo systemctl daemon-reload

Копирование данных (файлов) на удаленный сервер (например, aws):
scp -i <путь к ключу .pem> <путь к копируемому файлу> ubuntu@ec2...amazonaws.com:/home/ubuntu/ 

Адрес сервиса по проверке действительности ssl-сертификатов:
www.sslshopper.com/ssl-checker.html

Тестирование производительности web-приложения с помощью утилиты ab
-------------------------------------------------------------------
sudo apt-get install apache2-utils

ab -c 5 -n 100 https://docent63.ru

где -с - количество параллельных запросов, отправляемых одновременно
-n - общее число отправляемых запросов


